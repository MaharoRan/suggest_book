# ğŸ“š GUIDE COMPLET - SystÃ¨me de Recommandation LittÃ©raire

## EFREI M1 - Data Engineering & IA GÃ©nÃ©rative

---

## ğŸ¯ VUE D'ENSEMBLE

Ce systÃ¨me rÃ©pond aux **Exigences Fonctionnelles (EF)** du projet en combinant :

- **NLP local** (SBERT - coÃ»t zÃ©ro)
- **SimilaritÃ© cosinus** (matching sÃ©mantique)
- **GenAI stratÃ©gique** (enrichissement conditionnel + synthÃ¨se finale)

---

## ğŸ“‹ ARCHITECTURE DU SYSTÃˆME

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EF1 : ACQUISITION DONNÃ‰ES (Questionnaire)                  â”‚
â”‚  â”œâ”€ Questions ouvertes (description, livres prÃ©fÃ©rÃ©s)       â”‚
â”‚  â””â”€ Questions Likert 1-5 (action, romance, complexitÃ©)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EF2 : MOTEUR NLP SÃ‰MANTIQUE (Local, Gratuit)              â”‚
â”‚  â”œâ”€ RÃ©fÃ©rentiel : 700+ livres (EF2.1)                      â”‚
â”‚  â”œâ”€ SBERT Embeddings : 384 dimensions (EF2.2)              â”‚
â”‚  â””â”€ SimilaritÃ© Cosinus (EF2.3)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EF4.1 : AUGMENTATION PRE-PROCESSING (Conditionnelle)      â”‚
â”‚  â””â”€ Si texte < 5 mots â†’ GenAI enrichit le contexte         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EF3 : SCORING & RECOMMANDATION                             â”‚
â”‚  â”œâ”€ Score pondÃ©rÃ© : 80% similaritÃ© + 20% intensitÃ© (EF3.1) â”‚
â”‚  â””â”€ Top 3 livres recommandÃ©s (EF3.2)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EF4.2-4.3 : SYNTHÃˆSE GENAI (1 seul appel)                 â”‚
â”‚  â”œâ”€ Explication personnalisÃ©e (EF4.2)                      â”‚
â”‚  â””â”€ Executive Summary (EF4.3)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” EXPLICATIONS DÃ‰TAILLÃ‰ES DES MODULES

### **MODULE 1 : EF1 - Acquisition de la DonnÃ©e**

#### **Fonction : `collect_user_preferences()`**

**Ce qu'elle fait :**

- Pose un questionnaire **hybride** Ã  l'utilisateur
- Combine questions **ouvertes** et Ã©chelles **Likert (1-5)**

**Questions posÃ©es :**

1. **Questions ouvertes** (EF1.1)

   ```python
   - Description du livre recherchÃ© (libre)
   - Livres prÃ©fÃ©rÃ©s (rÃ©fÃ©rences)
   - Genres Ã  Ã©viter (exclusions)
   ```

2. **Questions numÃ©riques** (Ã‰chelle Likert 1-5)
   ```python
   - IntensitÃ© d'action souhaitÃ©e
   - IntÃ©rÃªt pour la romance
   - Importance de l'apprentissage
   - ComplexitÃ© narrative
   ```

**Pourquoi c'est important :**

- Les rÃ©ponses ouvertes capturent le **contexte sÃ©mantique**
- Les scores Likert permettent une **pondÃ©ration quantitative**
- Combinaison = analyse riche et nuancÃ©e

**Stockage (EF1.2) :**

```json
{
  "description": "Je cherche un thriller psychologique...",
  "favorite_books": "Gone Girl, The Silent Patient",
  "intensity_action": 5,
  "intensity_romance": 2,
  "timestamp": "2025-12-10T14:30:00"
}
```

---

### **MODULE 2 : EF2 - Moteur NLP SÃ©mantique**

#### **Fonction : `load_knowledge_base()`** (EF2.1)

**Ce qu'elle fait :**

- Charge le dataset de livres (CSV)
- Nettoie les donnÃ©es (supprime doublons, catÃ©gories invalides)
- CrÃ©e un **rÃ©fÃ©rentiel de connaissances** structurÃ©

**Transformation des donnÃ©es :**

```python
# Avant
Title: "The Great Gatsby"
Category: "Fiction"
Description: "A story of wealth and love..."

# AprÃ¨s nettoyage
text_full: "the great gatsby. fiction. a story of wealth and love..."
```

**Pourquoi `text_full` ?**

- Combine **titre + genre + description** en UN texte
- Permet Ã  SBERT de capturer le **contexte complet** du livre
- Plus d'information = meilleur embedding

---

#### **Fonction : `load_sbert_and_embeddings()`** (EF2.2)

**Ce qu'elle fait :**

- Charge le modÃ¨le **SentenceTransformer** (SBERT)
- GÃ©nÃ¨re des **embeddings** (vecteurs 384D) pour chaque livre
- Cache les rÃ©sultats pour Ã©viter de recalculer

**Qu'est-ce qu'un embedding ?**

```
Texte : "the great gatsby. fiction. a story of wealth..."
         â†“ SBERT
Vecteur : [0.24, -0.15, 0.89, ..., 0.33]  (384 nombres)
```

**Pourquoi SBERT ?**

- **Local** : Aucun coÃ»t, aucune API externe
- **Rapide** : Traite 700 livres en ~30 secondes
- **SÃ©mantique** : Capture le **sens** du texte, pas juste les mots

**Mise en cache :**

```python
# PremiÃ¨re exÃ©cution : gÃ©nÃ¨re et sauvegarde
embeddings_books.pkl  # 700 livres Ã— 384D â‰ˆ 2 MB

# ExÃ©cutions suivantes : charge depuis le fichier
# Gain de temps : 30s â†’ 1s
```

---

#### **Fonction : `calculate_weighted_similarity()`** (EF2.3 + EF3.1)

**Ce qu'elle fait :**

1. Calcule la **similaritÃ© cosinus** entre la requÃªte et un livre (EF2.3)
2. Applique une **pondÃ©ration** basÃ©e sur les scores Likert (EF3.1)

**Formule mathÃ©matique :**

```
SimilaritÃ© Cosinus = (A Â· B) / (||A|| Ã— ||B||)

OÃ¹ :
- A = vecteur embedding de la requÃªte utilisateur
- B = vecteur embedding du livre
- Â· = produit scalaire
- ||X|| = norme du vecteur

RÃ©sultat : Nombre entre 0 (aucune similaritÃ©) et 1 (identique)
```

**Exemple concret :**

```python
RequÃªte : "thriller psychologique avec suspense"
Livre 1 : "Gone Girl" (thriller psychologique)
Livre 2 : "Pride and Prejudice" (romance classique)

SimilaritÃ©s cosinus :
- Gone Girl        : 0.87  (trÃ¨s similaire)
- Pride & Prejudice : 0.23  (peu similaire)
```

**PondÃ©ration par intensitÃ©s (EF3.1) :**

```python
# Moyenne des scores Likert
avg_intensity = (5 + 2 + 3 + 4) / 4 / 5 = 0.70  (normalisÃ© 0-1)

# Score final pondÃ©rÃ©
weighted_score = 0.8 Ã— cosine_sim + 0.2 Ã— avg_intensity

# Exemple
Gone Girl : 0.8 Ã— 0.87 + 0.2 Ã— 0.70 = 0.836
```

**Pourquoi cette pondÃ©ration ?**

- **80% sÃ©mantique** : Le sens du texte est prioritaire
- **20% intensitÃ©** : Les prÃ©fÃ©rences numÃ©riques affinent le rÃ©sultat
- Balance entre matching contextuel et prÃ©fÃ©rences quantitatives

---

### **MODULE 3 : EF4.1 - Augmentation Pre-Processing**

#### **Fonction : `enrich_short_query()`**

**Ce qu'elle fait :**

- DÃ©tecte si la requÃªte utilisateur est **trop courte** (< 5 mots)
- Si OUI â†’ Appelle GenAI pour enrichir le contexte
- Si NON â†’ Utilise le texte original

**Exemple d'enrichissement :**

```python
# Texte utilisateur (3 mots)
Input : "thriller suspense"

# AprÃ¨s enrichissement GenAI
Output : "thriller suspense avec intrigue psychologique complexe,
          retournements de situation et ambiance sombre et oppressante"
```

**Pourquoi c'est utile ?**

- SBERT fonctionne mieux avec du **contexte riche**
- 3 mots = embedding pauvre, rÃ©sultats moins prÃ©cis
- Enrichissement = plus d'informations pour le matching

**Usage conditionnel (EF4.1) :**

```python
if len(texte.split()) < 5:
    # UN SEUL appel API si nÃ©cessaire
    texte_enrichi = appel_genai(texte)
else:
    # Aucun coÃ»t si texte suffisant
    texte_enrichi = texte
```

**Fallback sans GenAI :**

- Si pas de clÃ© API â†’ enrichissement basique local
- Garantit que le systÃ¨me fonctionne **toujours**

---

### **MODULE 4 : EF3.2 - Recommandation Top 3**

#### **Fonction : `recommend_books()`**

**Ce qu'elle fait :**

1. Construit une requÃªte sÃ©mantique complÃ¨te
2. Encode la requÃªte en embedding
3. Calcule les scores pour TOUS les livres
4. Retourne les **3 meilleurs**

**Pipeline complet :**

```python
# 1. Construction de la requÃªte
preferences = {
    'description': "thriller psychologique",
    'favorite_books': "Gone Girl",
    'intensity_action': 5
}
         â†“
query_text = "thriller psychologique. Livres similaires Ã  Gone Girl.
              trÃ¨s intense. romance lÃ©gÃ¨re. instructif. complexe"

# 2. Enrichissement (si < 5 mots)
query_enriched = enrich_short_query(query_text)

# 3. Embedding
query_emb = SBERT.encode(query_enriched)  # [0.21, -0.45, ..., 0.89]

# 4. Calcul des scores
scores = []
for livre in tous_les_livres:
    score = calculate_weighted_similarity(query_emb, livre.embedding)
    scores.append(score)

# 5. Top 3
indices_top3 = argsort(scores)[:3]
```

**Format des rÃ©sultats :**

```python
[
    {
        'rank': 1,
        'title': 'The Silent Patient',
        'genre': 'Mystery Thriller',
        'similarity_score': 0.8634,
        'description': '...'
    },
    {
        'rank': 2,
        'title': 'Sharp Objects',
        'genre': 'Mystery Thriller',
        'similarity_score': 0.8421,
        'description': '...'
    },
    {
        'rank': 3,
        'title': 'The Girl on the Train',
        'genre': 'Mystery Thriller',
        'similarity_score': 0.8189,
        'description': '...'
    }
]
```

---

### **MODULE 5 : EF4.2 & EF4.3 - SynthÃ¨se GenAI**

#### **Fonction : `generate_personalized_summary()`**

**Ce qu'elle fait :**

- GÃ©nÃ¨re une **synthÃ¨se personnalisÃ©e** expliquant les recommandations
- **UN SEUL appel API** (Ã©conomie de coÃ»ts)
- Format **Executive Summary** professionnel

**Prompt envoyÃ© Ã  Gemini :**

```
Tu es un conseiller littÃ©raire expert.

PROFIL LECTEUR :
thriller psychologique avec suspense intense...

LIVRE RECOMMANDÃ‰ (Score : 0.863) :
- Titre : The Silent Patient
- Genre : Mystery Thriller
- RÃ©sumÃ© : A shocking psychological thriller...

MISSION :
1. Explique POURQUOI ce livre correspond (4-5 phrases)
2. Identifie 2-3 aspects parfaitement couverts
3. Propose une orientation de lecture complÃ©mentaire
```

**Exemple de synthÃ¨se gÃ©nÃ©rÃ©e :**

```
ğŸ§  SYNTHÃˆSE PERSONNALISÃ‰E :

"The Silent Patient" correspond parfaitement Ã  votre profil de lecteur
recherchant une tension psychologique intense. Le rÃ©cit combine l'intrigue
criminelle que vous apprÃ©ciez dans "Gone Girl" avec une profondeur
psychologique encore plus marquÃ©e, explorant les traumatismes et le silence
comme armes narratives.

ASPECTS COUVERTS :
âœ“ Suspense psychologique trÃ¨s intense (correspond Ã  votre score 5/5)
âœ“ ComplexitÃ© narrative avec retournements surprenants
âœ“ Ambiance sombre et oppressante

ORIENTATION COMPLÃ‰MENTAIRE :
Pour enrichir votre parcours, explorez ensuite les thrillers nordiques
(Stieg Larsson, Jo NesbÃ¸) qui prolongent cette atmosphÃ¨re tout en ajoutant
une dimension sociale et politique.
```

**Pourquoi UN SEUL appel ?**

- CoÃ»t maÃ®trisÃ© : ~$0.001 par requÃªte
- ConformitÃ© EF4.2 : "Un seul appel API pour la sortie finale"
- Valeur maximale : synthÃ¨se complÃ¨te en une fois

---

## ğŸ”§ CONCEPTS TECHNIQUES Ã€ RETENIR

### **1. Embeddings (Vecteurs SÃ©mantiques)**

**DÃ©finition :**
Transformation d'un texte en vecteur de nombres qui capture son **sens**.

```python
Texte â†’ [n1, n2, n3, ..., n384]
```

**PropriÃ©tÃ© magique :**
Des textes **similaires** ont des vecteurs **proches** dans l'espace.

**Exemple :**

```
"chat"          â†’ [0.8, 0.2, -0.1, ...]
"chien"         â†’ [0.7, 0.3, -0.2, ...]  (proche de chat)
"ordinateur"    â†’ [-0.1, -0.5, 0.9, ...] (loin de chat)
```

---

### **2. SimilaritÃ© Cosinus**

**DÃ©finition :**
Mesure l'**angle** entre deux vecteurs (0Â° = identique, 90Â° = orthogonal).

**Formule simplifiÃ©e :**

```
cos(Î¸) = Somme(A Ã— B) / (Longueur(A) Ã— Longueur(B))
```

**InterprÃ©tation :**

```
1.0  = Textes identiques
0.8+ = TrÃ¨s similaires (recommandation forte)
0.5  = Moyennement similaires
0.0  = Aucun lien
```

---

### **3. DiffÃ©rence SBERT vs Word2Vec/GloVe**

| Aspect      | Word2Vec/GloVe   | SBERT               |
| ----------- | ---------------- | ------------------- |
| **Niveau**  | Mots individuels | Phrases/Paragraphes |
| **Context** | FenÃªtre locale   | Contexte global     |
| **Taille**  | ~300D            | 384-768D            |
| **Usage**   | Analyse de mots  | Matching de textes  |

**Exemple :**

```python
# Word2Vec
"apple" â†’ vecteur fruit/tech (ambiguÃ¯tÃ©)

# SBERT
"I love eating apples" â†’ vecteur clairement fruit
"Apple released iPhone" â†’ vecteur clairement tech
```

---

### **4. PondÃ©ration des Scores**

**Pourquoi 80/20 ?**

```python
score_final = 0.8 Ã— similaritÃ©_cosinus + 0.2 Ã— intensitÃ©_likert
```

**Justification :**

- **80% sÃ©mantique** : Le texte contient l'information principale
- **20% intensitÃ©** : Ajuste selon les prÃ©fÃ©rences quantifiÃ©es
- Ã‰vite que des scores Likert "forts" masquent une faible similaritÃ© textuelle

**Exemple comparatif :**

```
Livre A : SimilaritÃ© 0.9, IntensitÃ© 0.5
Score = 0.8Ã—0.9 + 0.2Ã—0.5 = 0.82

Livre B : SimilaritÃ© 0.5, IntensitÃ© 0.9
Score = 0.8Ã—0.5 + 0.2Ã—0.9 = 0.58

â†’ Livre A gagne (sÃ©mantique prime)
```

---

## ğŸš€ UTILISATION DU SYSTÃˆME

### **Sans GenAI (Gratuit, Local)**

```bash
python book_recommendation_system.py
```

Le systÃ¨me fonctionne **entiÃ¨rement** avec SBERT local.

### **Avec GenAI (Enrichissement + SynthÃ¨se)**

```bash
# Windows
set GEMINI_API_KEY=votre_clÃ©_ici
python book_recommendation_system.py

# Linux/Mac
export GEMINI_API_KEY=votre_clÃ©_ici
python book_recommendation_system.py
```

**Obtenir une clÃ© Gemini (gratuite) :**

1. Aller sur https://makersuite.google.com/app/apikey
2. CrÃ©er un projet
3. GÃ©nÃ©rer une clÃ© API
4. Limite gratuite : 60 requÃªtes/minute

---

## ğŸ“Š FLUX DE DONNÃ‰ES COMPLET

```
UTILISATEUR
    â†“ RÃ©pond au questionnaire
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Questions ouvertes + Likert     â”‚
â”‚ â†’ JSON structurÃ©                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Construction requÃªte sÃ©mantique â”‚
â”‚ â†’ "thriller + intense + ..."    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enrichissement (si texte court) â”‚
â”‚ â†’ GenAI ajoute contexte         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding SBERT                 â”‚
â”‚ â†’ Vecteur 384D                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Calcul similaritÃ© Ã— 700 livres  â”‚
â”‚ â†’ Scores pondÃ©rÃ©s               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Top 3 recommandations           â”‚
â”‚ â†’ Livres classÃ©s par score      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SynthÃ¨se GenAI (optionnel)      â”‚
â”‚ â†’ Explication personnalisÃ©e     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
RÃ‰SULTATS AFFICHÃ‰S
```

---

## ğŸ“ POINTS CLÃ‰S Ã€ RETENIR POUR L'EXAMEN

### **1. Architecture Hybride**

- **NLP local** (SBERT) = Base gratuite et performante
- **GenAI stratÃ©gique** = Enrichissement ciblÃ© et synthÃ¨se finale
- **Ã‰quilibre coÃ»t/valeur** : 95% local, 5% GenAI

### **2. ConformitÃ© aux Exigences**

- **EF1** âœ… : Questionnaire hybride (ouvert + Likert)
- **EF2** âœ… : RÃ©fÃ©rentiel + SBERT + Cosinus
- **EF3** âœ… : Scoring pondÃ©rÃ© + Top 3
- **EF4** âœ… : 2 appels GenAI max (enrichissement + synthÃ¨se)

### **3. Avantages de l'Approche**

- **ZÃ©ro coÃ»t en mode local**
- **Scalable** : Peut traiter 10K+ livres
- **PersonnalisÃ©** : Chaque utilisateur a des rÃ©sultats uniques
- **Explicable** : Scores de similaritÃ© transparents

### **4. AmÃ©liorations Possibles**

- **Filtrage collaboratif** : Ajouter les prÃ©fÃ©rences d'autres utilisateurs
- **Fine-tuning SBERT** : EntraÃ®ner sur des donnÃ©es littÃ©raires
- **Interface Web** : Flask/Streamlit pour l'IHM
- **Visualisation** : Graphiques radar des scores

---

## ğŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S

```
book_recommendation_system.py        # Code principal
user_preferences.json                # RÃ©ponses utilisateur
embeddings_books.pkl                 # Cache des embeddings
recommendation_results.json          # RÃ©sultats finaux
```

---

## âœ… CHECKLIST DE COMPRÃ‰HENSION

- [ ] Je comprends ce qu'est un **embedding**
- [ ] Je peux expliquer la **similaritÃ© cosinus**
- [ ] Je sais pourquoi SBERT > Word2Vec pour ce cas
- [ ] Je comprends la **pondÃ©ration 80/20**
- [ ] Je peux justifier l'**usage conditionnel** de GenAI
- [ ] Je sais mapper chaque fonction Ã  une exigence (EF1-EF4)

---

**Bon courage pour ton projet ! ğŸš€**
